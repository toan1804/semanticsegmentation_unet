{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input/lyft-udacity-challenge/dataA/dataA'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-19T03:15:28.239915Z","iopub.execute_input":"2021-07-19T03:15:28.240286Z","iopub.status.idle":"2021-07-19T03:15:28.248792Z","shell.execute_reply.started":"2021-07-19T03:15:28.240205Z","shell.execute_reply":"2021-07-19T03:15:28.247923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, Dropout, Conv2DTranspose, MaxPooling2D, concatenate\nimport imageio\nimport cv2\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:19:02.24034Z","iopub.execute_input":"2021-07-19T03:19:02.240742Z","iopub.status.idle":"2021-07-19T03:19:02.388614Z","shell.execute_reply.started":"2021-07-19T03:19:02.240708Z","shell.execute_reply":"2021-07-19T03:19:02.387745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = ''\nimage_path = os.path.join(path, '/kaggle/input/lyft-udacity-challenge/dataA/dataA/CameraRGB/')\nmask_path = os.path.join(path, '/kaggle/input/lyft-udacity-challenge/dataA/dataA/CameraSeg/')\nimage_list = os.listdir(image_path)\nmask_list = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:15:36.282665Z","iopub.execute_input":"2021-07-19T03:15:36.283012Z","iopub.status.idle":"2021-07-19T03:15:36.545835Z","shell.execute_reply.started":"2021-07-19T03:15:36.282977Z","shell.execute_reply":"2021-07-19T03:15:36.544983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CHECK IMAGE","metadata":{}},{"cell_type":"code","source":"N = 12\n\nimg = imageio.imread(image_list[N])\nmask = imageio.imread(mask_list[N])\nmask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\nmask = cv2.addWeighted(img/255.,0.5, mask, 0.5, 0)\nfig, arr = plt.subplots(1, 2, figsize=(14, 10))\narr[0].imshow(img)\narr[0].set_title('Image')\narr[1].imshow(mask, cmap='Paired')\narr[1].set_title('Segmentation')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:19:32.339932Z","iopub.execute_input":"2021-07-19T03:19:32.340269Z","iopub.status.idle":"2021-07-19T03:19:34.622424Z","shell.execute_reply.started":"2021-07-19T03:19:32.340232Z","shell.execute_reply":"2021-07-19T03:19:34.620471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:20:08.327921Z","iopub.execute_input":"2021-07-19T03:20:08.32827Z","iopub.status.idle":"2021-07-19T03:20:08.33425Z","shell.execute_reply.started":"2021-07-19T03:20:08.328234Z","shell.execute_reply":"2021-07-19T03:20:08.33333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:20:25.923606Z","iopub.execute_input":"2021-07-19T03:20:25.923937Z","iopub.status.idle":"2021-07-19T03:20:25.932397Z","shell.execute_reply.started":"2021-07-19T03:20:25.923911Z","shell.execute_reply":"2021-07-19T03:20:25.931531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_filenames = tf.constant(image_list)\nmasks_filenames = tf.constant(mask_list)\n\ndataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n\nfor image, mask in dataset.take(3):\n    print(image)\n    print(mask)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:10:33.924461Z","iopub.execute_input":"2021-07-19T03:10:33.924824Z","iopub.status.idle":"2021-07-19T03:10:33.937472Z","shell.execute_reply.started":"2021-07-19T03:10:33.92479Z","shell.execute_reply":"2021-07-19T03:10:33.936588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing image","metadata":{}},{"cell_type":"code","source":"def process_path(image_path, mask_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    mask = tf.io.read_file(mask_path)\n    mask = tf.image.decode_png(mask, channels=3)\n    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n    return img, mask\n\ndef preprocess(image, mask):\n    input_image = tf.image.resize(image, (192, 256), method='nearest')\n    input_mask = tf.image.resize(mask, (192, 256), method='nearest')\n\n    input_image = input_image / 255.\n\n    return input_image, input_mask\n\nimage_ds = dataset.map(process_path)\nprocessed_image_ds = image_ds.map(preprocess)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:11:43.879873Z","iopub.execute_input":"2021-07-19T03:11:43.880231Z","iopub.status.idle":"2021-07-19T03:11:43.960249Z","shell.execute_reply.started":"2021-07-19T03:11:43.880195Z","shell.execute_reply":"2021-07-19T03:11:43.959317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build block U-net","metadata":{}},{"cell_type":"code","source":"def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n    \n    conv = Conv2D(n_filters,\n                 3,\n                 activation = 'relu',\n                 padding = 'same',\n                 kernel_initializer = 'he_normal')(inputs)\n    conv = Conv2D(n_filters,\n                 3,\n                 activation = 'relu',\n                 padding = 'same',\n                 kernel_initializer = 'he_normal')(conv)\n\n    if dropout_prob > 0:\n         conv = Dropout(dropout_prob)(conv)\n         \n    if max_pooling:\n        next_layer = MaxPooling2D(pool_size = (2,2))(conv)\n        \n    else:\n        next_layer = conv\n        \n    skip_connection = conv\n    \n    return next_layer, skip_connection\n\ndef upsampling_block(expansive_input, contractive_input, n_filters=32):\n\n    up = Conv2DTranspose(n_filters,\n                        3,\n                        strides = (2,2),\n                        padding = 'same')(expansive_input)\n    merge = concatenate([up, contractive_input],axis = 3)\n    conv = Conv2D(n_filters,\n                 3,\n                 activation = 'relu',\n                 padding = 'same',\n                 kernel_initializer = 'he_normal')(merge)\n    conv = Conv2D(n_filters,\n                 3,\n                 activation = 'relu',\n                 padding = 'same',\n                 kernel_initializer = 'he_normal')(conv)\n    \n    return conv","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:11:47.228078Z","iopub.execute_input":"2021-07-19T03:11:47.228524Z","iopub.status.idle":"2021-07-19T03:11:47.237416Z","shell.execute_reply.started":"2021-07-19T03:11:47.22849Z","shell.execute_reply":"2021-07-19T03:11:47.236562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UNET Architecture","metadata":{}},{"cell_type":"code","source":"def unet_model(input_size=(192, 256, 3), n_filters=32, n_classes=13):\n    \n    inputs = Input(input_size)\n   \n    cblock1 = conv_block(inputs=inputs, n_filters=n_filters)\n    cblock2 = conv_block(inputs = cblock1[0],n_filters = 2*n_filters)\n    cblock3 = conv_block(inputs = cblock2[0],n_filters = 4*n_filters)\n    cblock4 = conv_block(inputs = cblock3[0],n_filters = 8*n_filters, dropout_prob = 0.3)\n    cblock5 = conv_block(inputs = cblock4[0], n_filters = 16*n_filters, dropout_prob = 0.3, max_pooling = False)\n    \n    ublock6 = upsampling_block(cblock5[0],cblock4[1],n_filters = 8 * n_filters)\n    ublock7 = upsampling_block(ublock6,cblock3[1],n_filters = 4 * n_filters)\n    ublock8 = upsampling_block(ublock7,cblock2[1],n_filters = 2 * n_filters)\n    ublock9 = upsampling_block(ublock8,cblock1[1],n_filters = n_filters)\n\n    conv9 = Conv2D(n_filters,\n                 3,\n                 activation='relu',\n                 padding='same',\n                 kernel_initializer='he_normal')(ublock9)\n\n    conv10 = Conv2D(n_classes, 1, padding = 'same')(conv9)\n\n    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:09:38.607364Z","iopub.execute_input":"2021-07-19T03:09:38.607702Z","iopub.status.idle":"2021-07-19T03:09:38.617982Z","shell.execute_reply.started":"2021-07-19T03:09:38.60767Z","shell.execute_reply":"2021-07-19T03:09:38.616517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = 192\nimg_width = 256\nnum_channels = 3\n\nunet = unet_model((img_height, img_width, num_channels))","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:12:12.852131Z","iopub.execute_input":"2021-07-19T03:12:12.852487Z","iopub.status.idle":"2021-07-19T03:12:13.190108Z","shell.execute_reply.started":"2021-07-19T03:12:12.852455Z","shell.execute_reply":"2021-07-19T03:12:13.189259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:12:15.799801Z","iopub.execute_input":"2021-07-19T03:12:15.800164Z","iopub.status.idle":"2021-07-19T03:12:15.820293Z","shell.execute_reply.started":"2021-07-19T03:12:15.800129Z","shell.execute_reply":"2021-07-19T03:12:15.819454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Set optimizer, loss and metrics","metadata":{}},{"cell_type":"code","source":"unet.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:14:34.908592Z","iopub.execute_input":"2021-07-19T03:14:34.909267Z","iopub.status.idle":"2021-07-19T03:14:34.924349Z","shell.execute_reply.started":"2021-07-19T03:14:34.909228Z","shell.execute_reply":"2021-07-19T03:14:34.923582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display(display_list):\n    plt.figure(figsize=(15, 15))\n\n    title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:14:37.028077Z","iopub.execute_input":"2021-07-19T03:14:37.028411Z","iopub.status.idle":"2021-07-19T03:14:37.034436Z","shell.execute_reply.started":"2021-07-19T03:14:37.028384Z","shell.execute_reply":"2021-07-19T03:14:37.033369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visual image","metadata":{}},{"cell_type":"code","source":"for image, mask in image_ds.take(1):\n    sample_image, sample_mask = image, mask\n    print(mask.shape)\ndisplay([sample_image, sample_mask])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:14:39.819943Z","iopub.execute_input":"2021-07-19T03:14:39.820287Z","iopub.status.idle":"2021-07-19T03:14:40.175234Z","shell.execute_reply.started":"2021-07-19T03:14:39.820255Z","shell.execute_reply":"2021-07-19T03:14:40.174413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image, mask in processed_image_ds.take(1):\n    sample_image, sample_mask = image, mask\n    print(mask.shape)\ndisplay([sample_image, sample_mask])","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:14:43.060397Z","iopub.execute_input":"2021-07-19T03:14:43.060773Z","iopub.status.idle":"2021-07-19T03:14:43.346389Z","shell.execute_reply.started":"2021-07-19T03:14:43.060738Z","shell.execute_reply":"2021-07-19T03:14:43.345792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TRAINING ","metadata":{}},{"cell_type":"code","source":"EPOCHS = 80\nVAL_SUBSPLITS = 5\nBUFFER_SIZE = 500\nBATCH_SIZE = 32\nprocessed_image_ds.batch(BATCH_SIZE)\ntrain_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\nprint(processed_image_ds.element_spec)\nmodel_history = unet.fit(train_dataset, epochs=EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2021-07-19T03:14:46.167876Z","iopub.execute_input":"2021-07-19T03:14:46.168385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SAVE model","metadata":{}},{"cell_type":"code","source":"unet.save('unet_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T01:30:00.133317Z","iopub.execute_input":"2021-07-02T01:30:00.133645Z","iopub.status.idle":"2021-07-02T01:30:00.452099Z","shell.execute_reply.started":"2021-07-02T01:30:00.133614Z","shell.execute_reply":"2021-07-02T01:30:00.451024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet.load_weights('../input/unet-out/unet_model (1).h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T01:02:00.896071Z","iopub.execute_input":"2021-07-02T01:02:00.896392Z","iopub.status.idle":"2021-07-02T01:02:01.981934Z","shell.execute_reply.started":"2021-07-02T01:02:00.896361Z","shell.execute_reply":"2021-07-02T01:02:01.979444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_mask(pred_mask):\n    pred_mask = tf.argmax(pred_mask, axis=-1)\n    pred_mask = pred_mask[..., tf.newaxis]\n    return pred_mask[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-02T01:57:16.592012Z","iopub.execute_input":"2021-07-02T01:57:16.592433Z","iopub.status.idle":"2021-07-02T01:57:16.603387Z","shell.execute_reply.started":"2021-07-02T01:57:16.592392Z","shell.execute_reply":"2021-07-02T01:57:16.602496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visual accuracy","metadata":{}},{"cell_type":"code","source":"plt.plot(model_history.history[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T01:57:18.57921Z","iopub.execute_input":"2021-07-02T01:57:18.57952Z","iopub.status.idle":"2021-07-02T01:57:18.703185Z","shell.execute_reply.started":"2021-07-02T01:57:18.579492Z","shell.execute_reply":"2021-07-02T01:57:18.702408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(model_history.history[\"loss\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-02T01:57:21.006678Z","iopub.execute_input":"2021-07-02T01:57:21.007009Z","iopub.status.idle":"2021-07-02T01:57:21.133233Z","shell.execute_reply.started":"2021-07-02T01:57:21.006979Z","shell.execute_reply":"2021-07-02T01:57:21.132281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"def show_predictions(dataset=None, num=12):\n    \"\"\"\n    Displays the first image of each of the num batches\n    \"\"\"\n    if dataset:\n        for image, mask in dataset.take(num):\n            pred_mask = unet.predict(image)\n            display([image[0], mask[0], create_mask(pred_mask)])\n    else:\n        display([sample_image, sample_mask,\n             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])\nshow_predictions(train_dataset, 12)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T02:28:05.781252Z","iopub.execute_input":"2021-07-02T02:28:05.781593Z","iopub.status.idle":"2021-07-02T02:28:15.274645Z","shell.execute_reply.started":"2021-07-02T02:28:05.78156Z","shell.execute_reply":"2021-07-02T02:28:15.27371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(y_true, y_pred):\n  '''\n  Computes IOU and Dice Score.\n\n  Args:\n    y_true (tensor) - ground truth label map\n    y_pred (tensor) - predicted label map\n  '''\n  \n  class_wise_iou = []\n  class_wise_dice_score = []\n\n  smoothening_factor = 0.00001\n\n  for i in range(12):\n    intersection = np.sum((y_pred == i) * (y_true == i))\n    y_true_area = np.sum((y_true == i))\n    y_pred_area = np.sum((y_pred == i))\n    combined_area = y_true_area + y_pred_area\n    \n    iou = (intersection + smoothening_factor) / (combined_area - intersection + smoothening_factor)\n    class_wise_iou.append(iou)\n    \n    dice_score =  2 * ((intersection + smoothening_factor) / (combined_area + smoothening_factor))\n    class_wise_dice_score.append(dice_score)\n\n  return class_wise_iou, class_wise_dice_score","metadata":{"execution":{"iopub.status.busy":"2021-07-02T01:58:27.915244Z","iopub.execute_input":"2021-07-02T01:58:27.915593Z","iopub.status.idle":"2021-07-02T01:58:27.923865Z","shell.execute_reply.started":"2021-07-02T01:58:27.915558Z","shell.execute_reply":"2021-07-02T01:58:27.922868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, mask = train_dataset.take(2)\nfor image, mask in train_dataset.take(2):\n    pred_mask = unet.predict(image)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T01:58:31.02695Z","iopub.execute_input":"2021-07-02T01:58:31.027288Z","iopub.status.idle":"2021-07-02T01:58:32.207011Z","shell.execute_reply.started":"2021-07-02T01:58:31.027259Z","shell.execute_reply":"2021-07-02T01:58:32.206122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mask = mask.numpy()\nmask\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T02:00:13.911944Z","iopub.execute_input":"2021-07-02T02:00:13.912261Z","iopub.status.idle":"2021-07-02T02:00:13.920718Z","shell.execute_reply.started":"2021-07-02T02:00:13.912232Z","shell.execute_reply":"2021-07-02T02:00:13.919676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_mask.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-02T02:00:25.765096Z","iopub.execute_input":"2021-07-02T02:00:25.765508Z","iopub.status.idle":"2021-07-02T02:00:25.774259Z","shell.execute_reply.started":"2021-07-02T02:00:25.765471Z","shell.execute_reply":"2021-07-02T02:00:25.773464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iou, dice_score = compute_metrics(mask, pred_mask)\nprint(iou,dice_score)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T02:24:27.986499Z","iopub.execute_input":"2021-07-02T02:24:27.986869Z","iopub.status.idle":"2021-07-02T02:24:28.181131Z","shell.execute_reply.started":"2021-07-02T02:24:27.986838Z","shell.execute_reply":"2021-07-02T02:24:28.180083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}